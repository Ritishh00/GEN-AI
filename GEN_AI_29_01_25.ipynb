{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0t4ZI2IwQB7qbMVR/c8YD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritishh00/GEN-AI/blob/main/GEN_AI_29_01_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Abl9YCMa5jEG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.losses import MeanSquaredError , KLDivergence , BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Import ModelCheckpoint and EarlyStopping from tensorflow.keras.callbacks instead of tensorflow.keras.optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import cov, trace, iscomplexobj, asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "from tensorflow.keras.datasets import cifar10  # Import the cifar10 dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # Load the CIFAR-10 dataset\n",
        "# %%\n"
      ],
      "metadata": {
        "id": "uhd14vrx9V8M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.0  # Normalize the training data\n",
        "x_test = x_test.astype('float32') / 255.0  # Normalize the testing data\n"
      ],
      "metadata": {
        "id": "5pULKc6H9tSM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 1024\n",
        "image_shape = x_train[0].shape  # Get the shape directly using .shape\n",
        "mse_loss = MeanSquaredError()\n",
        "kl_loss = KLDivergence()"
      ],
      "metadata": {
        "id": "jJtpMpZq-RUz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.losses import binary_crossentropy # Import binary_crossentropy\n",
        "\n",
        "\n",
        "class VAE(keras.Model):\n",
        "  def __init__(self, latent_dim, image_shape, beta):\n",
        "    super(VAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.beta=beta\n",
        "\n",
        "    self.encoder = keras.Sequential([\n",
        "        layers.Input(shape=image_shape, name=\"Encoder_Input_Layer\"),\n",
        "        layers.Conv2D(32, 3, strides=2, activation=\"relu\", padding='same', name=\"Encoder_Conv2D_2\"),\n",
        "        layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding='same', name=\"Encoder_Conv2D_4\"),\n",
        "        layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding='same', name=\"Encoder_Conv2D_6\"),\n",
        "        layers.Flatten(name=\"Encoder_Flatten\"),\n",
        "        ])\n",
        "\n",
        "    # First, define self.z to hold the mean and log_var layers.\n",
        "    self.z_mean = layers.Dense(latent_dim, name=\"z_Mean\")\n",
        "    self.z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")\n",
        "\n",
        "    self.decoder = keras.Sequential([\n",
        "        layers.InputLayer(input_shape=(latent_dim,)),\n",
        "        layers.Dense(8*8*64, activation='relu'),\n",
        "        layers.Reshape((8,8,64)),\n",
        "        layers.Conv2DTranspose(64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "        layers.Conv2DTranspose(32, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "        layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding='same', activation='sigmoid'),\n",
        "        ])\n",
        "\n",
        "    self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "    self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "    self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "  def encode(self,data):\n",
        "    x=self.encoder(data)\n",
        "    # Access z_mean and z_log_var directly\n",
        "    z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
        "    return z_mean, z_log_var\n",
        "\n",
        "  def reparameterization(self,z_mean, z_log_var):\n",
        "    batch=tf.shape(z_mean)[0]\n",
        "    dim=tf.shape(z_mean)[1]\n",
        "    epsilon=tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    z=z_mean+tf.exp(0.5*z_log_var)*epsilon\n",
        "    return z\n",
        "\n",
        "  def call(self,x):\n",
        "    mean, logvar=self.encode(x)\n",
        "    z=self.reparameterization(mean, logvar)\n",
        "    x_recon=self.decode(z)\n",
        "    return x_recon, mean, logvar\n",
        "\n",
        "  def decode(self,data):\n",
        "    return self.decoder(data)\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [\n",
        "        self.total_loss_tracker,\n",
        "        self.reconstruction_loss_tracker,\n",
        "        self.kl_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def recon_loss(self,data,reconstruction):\n",
        "    # Use binary_crossentropy from tensorflow.keras.losses\n",
        "    return tf.reduce_mean(binary_crossentropy(data,reconstruction))\n",
        "\n",
        "  def kl_divergence(self, Z_logvar, Z_mu):\n",
        "    kl_loss = -0.5 * tf.reduce_mean(1 + Z_logvar - Z_mu**2 - tf.math.exp(Z_logvar))\n",
        "    return self.beta*kl_loss # Return kl_loss instead of just kl\n",
        "\n",
        "  def train_step(self, data):\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var = self.encode(data)\n",
        "      z = self.reparameterization(z_mean, z_log_var)\n",
        "      reconstruction = self.decode(z)\n",
        "\n",
        "      reconstruction_loss = self.recon_loss(data, reconstruction)\n",
        "      kl_loss = self.kl_divergence(z_log_var, z_mean)\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "    self.total_loss_tracker.update_state(total_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "    self.kl_loss_tracker.update_state(kl_loss)\n",
        "    return {\n",
        "        \"loss\": self.total_loss_tracker.result(),\n",
        "        \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "        \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "    }"
      ],
      "metadata": {
        "id": "AL92GPX__npD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  vae = VAE(latent_dim, image_shape, 0.3)"
      ],
      "metadata": {
        "id": "XSpq8shfGsaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30112925-c5ac-466d-b390-0c85cfc7cbbc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
        "history = vae.fit(x_train, epochs=50, batch_size=512, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_ZKMRQOLzVS",
        "outputId": "2618cc1b-b5b4-4ae9-e2fa-ae108d4342ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - kl_loss: 7.3547e-04 - loss: 0.6868 - reconstruction_loss: 0.6860\n",
            "Epoch 2/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - kl_loss: 0.0081 - loss: 0.6280 - reconstruction_loss: 0.6199\n",
            "Epoch 3/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - kl_loss: 0.0107 - loss: 0.6189 - reconstruction_loss: 0.6082\n",
            "Epoch 4/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - kl_loss: 0.0124 - loss: 0.6145 - reconstruction_loss: 0.6021\n",
            "Epoch 5/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - kl_loss: 0.0130 - loss: 0.6118 - reconstruction_loss: 0.5988\n",
            "Epoch 6/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - kl_loss: 0.0134 - loss: 0.6109 - reconstruction_loss: 0.5975\n",
            "Epoch 7/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0139 - loss: 0.6093 - reconstruction_loss: 0.5953\n",
            "Epoch 8/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - kl_loss: 0.0139 - loss: 0.6076 - reconstruction_loss: 0.5937\n",
            "Epoch 9/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - kl_loss: 0.0136 - loss: 0.6053 - reconstruction_loss: 0.5917\n",
            "Epoch 10/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0130 - loss: 0.6019 - reconstruction_loss: 0.5890\n",
            "Epoch 11/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - kl_loss: 0.0126 - loss: 0.6000 - reconstruction_loss: 0.5874\n",
            "Epoch 12/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0126 - loss: 0.5986 - reconstruction_loss: 0.5860\n",
            "Epoch 13/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0126 - loss: 0.5978 - reconstruction_loss: 0.5852\n",
            "Epoch 14/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - kl_loss: 0.0127 - loss: 0.5967 - reconstruction_loss: 0.5841\n",
            "Epoch 15/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - kl_loss: 0.0128 - loss: 0.5954 - reconstruction_loss: 0.5827\n",
            "Epoch 16/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0127 - loss: 0.5956 - reconstruction_loss: 0.5829\n",
            "Epoch 17/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - kl_loss: 0.0128 - loss: 0.5943 - reconstruction_loss: 0.5815\n",
            "Epoch 18/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - kl_loss: 0.0129 - loss: 0.5945 - reconstruction_loss: 0.5816\n",
            "Epoch 19/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0129 - loss: 0.5946 - reconstruction_loss: 0.5817\n",
            "Epoch 20/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0130 - loss: 0.5940 - reconstruction_loss: 0.5810\n",
            "Epoch 21/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - kl_loss: 0.0130 - loss: 0.5937 - reconstruction_loss: 0.5807\n",
            "Epoch 22/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0131 - loss: 0.5931 - reconstruction_loss: 0.5800\n",
            "Epoch 23/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0131 - loss: 0.5940 - reconstruction_loss: 0.5809\n",
            "Epoch 24/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - kl_loss: 0.0132 - loss: 0.5935 - reconstruction_loss: 0.5804\n",
            "Epoch 25/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - kl_loss: 0.0132 - loss: 0.5936 - reconstruction_loss: 0.5804\n",
            "Epoch 26/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - kl_loss: 0.0132 - loss: 0.5931 - reconstruction_loss: 0.5799\n",
            "Epoch 27/50\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - kl_loss: 0.0132 - loss: 0.5928 - reconstruction_loss: 0.5796\n",
            "Epoch 28/50\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - kl_loss: 0.0133 - loss: 0.5910 - reconstruction_loss: 0.5777"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPF1wG9SQc3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}