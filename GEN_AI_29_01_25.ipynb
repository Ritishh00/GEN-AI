{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkgIOEuGF0eC/3LWV5jyYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritishh00/GEN-AI/blob/main/GEN_AI_29_01_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Abl9YCMa5jEG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.losses import MeanSquaredError , KLDivergence , BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Import ModelCheckpoint and EarlyStopping from tensorflow.keras.callbacks instead of tensorflow.keras.optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import cov, trace, iscomplexobj, asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10  # Import the cifar10 dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # Load the CIFAR-10 dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhd14vrx9V8M",
        "outputId": "f8e75c08-1967-44b8-f3b6-c4a24a8ba389"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.0  # Normalize the training data\n",
        "x_test = x_test.astype('float32') / 255.0  # Normalize the testing data"
      ],
      "metadata": {
        "id": "5pULKc6H9tSM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 1024\n",
        "image_shape = x_train[0].shape  # Get the shape directly using .shape\n",
        "mse_loss = MeanSquaredError()\n",
        "kl_loss = KLDivergence()"
      ],
      "metadata": {
        "id": "jJtpMpZq-RUz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(Model):\n",
        "    def __init__(self, latent_dim, image_shape, beta):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.image_shape = image_shape\n",
        "        self.beta = beta\n",
        "\n",
        "        #encoder\n",
        "        self.encoder = keras.Sequential([\n",
        "            layers.Input(shape=image_shape, name=\"Encoder_input_layer\"),\n",
        "            layers.Conv2D(32, 3, strides=2, activation='relu', padding='same' , name=\"Encoder_Conv2D_2\"),\n",
        "             layers.Conv2D(64, 3, strides=2, activation='relu', padding='same' , name=\"Encoder_Conv2D_4\"),\n",
        "              layers.Conv2D(128, 3, strides=2, activation='relu', padding='same' , name=\"Encoder_Conv2D_6\"),\n",
        "              layers.Flatten(name=\"Encoder_Flatten\")\n",
        "        ])\n",
        "\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "\n",
        "    #build the Encoder\n",
        "    def encoder(self,data):\n",
        "        x = self.encoder(data)\n",
        "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
        "        return z_mean, z_log_var\n",
        "\n",
        "    # build the reparmeterization/sampling layer\n",
        "    def reparametrization(self, z_mean, z_log_var):\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        z = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "        return z\n",
        "\n",
        "    def decode(self, data):\n",
        "        return self.decoder(data)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def recon_loss(self,data,reconstruction):\n",
        "        return tf.reduce_mean(binary_crossentropy(data,reconstruction))\n",
        "\n",
        "    def kl_divergence(self, Z_logvar, Z_mu): # Corrected indentation here\n",
        "        kl_loss = -0.5 * tf.reduce_mean(1 + Z_logvar - Z_mu**2 - tf.math.exp(Z_logvar))\n",
        "        return self.beta*kl\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var = self.encode(data)\n",
        "            z = self.reparameterization(z_mean, z_log_var)\n",
        "            reconstruction = self.decode(z)"
      ],
      "metadata": {
        "id": "AL92GPX__npD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XSpq8shfGsaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}